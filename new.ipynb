{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "pdf_file_path = 'C:/Users/sriyo/Desktop/jets/NLP Bot/files/ML.pdf'\n",
    "\n",
    "def extract_text_with_spaces(file_path):\n",
    "    extracted_text = \"\"\n",
    "\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        num_pages = len(pdf.pages)\n",
    "        for page_num in range(num_pages):\n",
    "            page = pdf.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            extracted_text += f\"Page {page_num + 1}:\\n{text}\\n\"\n",
    "\n",
    "    return extracted_text\n",
    "\n",
    "pdf_text = extract_text_with_spaces(pdf_file_path)\n",
    "\n",
    "\n",
    "print(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def extract_and_preprocess_text(file_path):\n",
    "    preprocessed_texts = [] \n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        num_pages = len(pdf.pages)\n",
    "\n",
    "        for page_num in range(num_pages):\n",
    "            page = pdf.pages[page_num]\n",
    "            text = page.extract_text()\n",
    "            preprocessed_text = preprocess_text(text)\n",
    "            preprocessed_texts.append(preprocessed_text)\n",
    "\n",
    "            print(f\"Page {page_num + 1}:\\n{preprocessed_text}\\n\")\n",
    "\n",
    "    return preprocessed_texts \n",
    "\n",
    "\n",
    "pdf_file_path = 'C:/Users/sriyo/Desktop/jets/NLP Bot/files/ML.pdf'\n",
    "preprocessed_texts = extract_and_preprocess_text(pdf_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "all_Sentence=[]\n",
    "def tokenize_into_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "\n",
    "for preprocessed_text in preprocessed_texts:\n",
    "    sentences = tokenize_into_sentences(preprocessed_text)\n",
    "    print(sentences)\n",
    "    all_Sentence.append(sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Questions:\n",
      "What does machine learning behave like?\n",
      "How many times did the baby repeat the task 100 times?\n",
      "What is the term machine learning coined by?\n",
      "What does machine learning algorithms learn by experience similar to?\n",
      "What is the field of study that gives computers the ability to learn without being explicitly programmed?\n",
      "What did the baby figure out?\n",
      "What is the study of computer algorithms that allow computer programs to automatically improve through experience?\n",
      "What can be thought of as a set of rulesinstructions that a?\n",
      "What is machine learning programming computers to do?\n",
      "What is the performance measurep of the child in her first attempt at finding a shaped hole?\n",
      "What is the child's first reaction to the task?\n",
      "What can a machine learning algorithm recognize after seeing multiple examples of an object?\n",
      "What is the child's answer to the question?\n",
      "What results in higher performance measure p?\n",
      "What is the term machine learning used?\n",
      "What can a machine learning algorithm recognize in new previously unseen scenarios?\n",
      "What does a child's experience e in performing task t increase?\n",
      "What is the child's reaction to the task?\n",
      "What text does the text of the question generate?\n",
      "What is the toy that has three shapes?\n",
      "What is machine learning?\n",
      "What does the child observe and try to fit in a shaped hole?\n",
      "How many correct shape holes did the child find?\n",
      "What can be thought of as a set of rulesinstructions that a computer programmer specifies which a computer can process?\n",
      "What do we know about the different shapes and shape holes in the toy?\n",
      "What is the task of the text?\n",
      "What is the field of study that gives computers the capability to learn without being explicitly programmed?\n",
      "What is the result of the child attempting a task again?\n",
      "What is the field of study that gives computers?\n",
      "What is the term machine learning used for?\n",
      "?\n",
      "What toy is given to a child to sort shapes?\n",
      "Generated Questions:\n",
      "What does higher accuracy mean?\n",
      "What is the ability of machine learning to automate?\n",
      "What does a machine measure?\n",
      "What is the purpose of machine learning continuous improvement?\n",
      "What does a machine process as it processes data?\n",
      "What is the model accuracy and efficiency to make decisions improve with subsequent training?\n",
      "What does a machine experience as it processes data?\n",
      "What is the name of the company that collects a huge volume of new data every day?\n",
      "What is used in every industry these days?\n",
      "What is the power of machine learning?\n",
      "What is the question that you want to ask for the following text?\n",
      "What is the wide range of applications of machine learning?\n",
      "What is similar to machine learning?\n",
      "What is the name of the system that Amazon uses to predict products for its customers?\n",
      "What is the name of the application that uses gps tracking?\n",
      "What does a machine do?\n",
      "What is the name of the text that you want to use to answer the question?\n",
      "What is the name of the text that you want to use to?\n",
      "What do companies generate profits cut costs automate predict the future analyze trends and patterns from past data and many more?\n",
      "What?\n",
      "?\n",
      "What did the number of attempts at this toy increase?\n",
      "What is the name of the system that Amazon uses to predict products?\n",
      "What does the increase in accuracy mean for our machine learning models?\n",
      "Generated Questions:\n",
      "What is the universally accepted definition of machine learning?\n",
      "What?\n",
      "?\n",
      "What is the execution of a computer program to optimize the parameters of the model?\n",
      "What did he define machine learning as?\n",
      "What is the execution of a computer program to optimize the parameters of the model using the training data or past experience?\n",
      "What can the model be used to make?\n",
      "What term did arthur samuel coin in 1959?\n",
      "What is the definition of the term \"difficult\"?\n",
      "What is the definition of learning?\n",
      "What is machine learning?\n",
      "What can the model be used to gain knowledge from?\n",
      "What does the term \"difficult\" mean?\n",
      "What is machine learning programming computers to do?\n",
      "What did he define as the field of study that gives computers the ability to learn without being explicitly programmed?\n",
      "Generated Questions:\n",
      "What can be used to work with new input to give one an output?\n",
      "What makes it ml?\n",
      "?\n",
      "What is the second step in coding rules?\n",
      "What does a machine learning algorithm take input and an output and give?\n",
      "What does a machine learning algorithm take input and an output and give the some logic?\n",
      "What does machine learning automatically formulate the rules from?\n",
      "What is the logic generated for?\n",
      "Traditional programming is a manual process meaning a person programmer creates the program?\n",
      "What is traditional programming vs machine learning algorithms?\n",
      "What is the first step in coding rules?\n",
      "What does a traditional algorithm take input and some logic in the form of code and drums up the output machine learning?\n",
      "Generated Questions:\n",
      "What could each 0?\n",
      "What is the quality of the model depends upon various on the quality of the code?\n",
      "What do ml algorithms do not depend on?\n",
      "What do statisticians emphasize on in their models?\n",
      "What is the primary goal in machine learning models?\n",
      "What is the primary objective in machine learning models?\n",
      "What is the quality of the software primary depends upon?\n",
      "What is the name of the software stack that is used to create machine?\n",
      "What could each of these algorithms result in different performance?\n",
      "What is statistical modeling generally?\n",
      "What is the name of the question that you can use to generate a question for the following text?\n",
      "What is the name of the software stack that is used to create machine learning models?\n",
      "What are the main reasons for uninterruptability of ml models?\n",
      "What is the most work well question?\n",
      "What is the main difference between the two schools of thought?\n",
      "What is a learning system if it is not programme?\n",
      "What is the name of the software stack that is used to create traditional software?\n",
      "What is the best way to evaluate a model against incoming data?\n",
      "What is the main relationship between the input data and hyper parameters tuning?\n",
      "What is the name of the text that you want to use to answer the question?\n",
      "What could every 0?\n",
      "What is the name of the text that you want to use to?\n",
      "What type of data does the company process instead of raw form?\n",
      "What are the parameters related to?\n",
      "?\n",
      "What is not feasible due to the environment being constantly changing?\n",
      "What is the best way to train a model based on historical training data?\n",
      "What is a learning system if it is not programmed to perform a task but is programmed to learn to perform the task?\n",
      "1 improvement in the model metrics result in?\n",
      "Generated Questions:\n",
      "What is the cost of learning a very complex model of a highly dynamic network environment?\n",
      "?\n",
      "What is the second step of data gathering?\n",
      "What can be done by web scraping?\n",
      "What is the objective of the study of weather conditions?\n",
      "What is the objective of the problem statement?\n",
      "What is the third step of data gathering?\n",
      "What is the result of traditional ml approaches?\n",
      "What can be done manually or by web scraping?\n",
      "What is the cost of traditional ml approaches?\n",
      "What is the first step of data gathering?\n",
      "What is the difference between classical approaches?\n",
      "What is the first step in solving a problem?\n",
      "What is the answer to the question that you want to answer?\n",
      "What is one of the key differences between classical approaches and machine learning algorithms?\n",
      "What is the difference between classical approaches and machine learning algorithms?\n",
      "Generated Questions:\n",
      "What is the third step of data preparation?\n",
      "What must be collected and stored for analysis?\n",
      "What must be understood and mapped at this stage?\n",
      "What is the last step in building a model?\n",
      "What is the test data set used to check?\n",
      "What will be used to build and analyze the model?\n",
      "What can be used to improve the performance of a model?\n",
      "What is the first step of exploratory data analysis?\n",
      "What is the first step in the training phase?\n",
      "What can be a continuous quantity eg?\n",
      "What is the brainstorming stage of machine learning?\n",
      "What is the possibility of rain if the temperature has fallen low?\n",
      "What is the reason for inconsistencies in the data set?\n",
      "What is the second step of data preparation?\n",
      "What is used to check the accuracy of the model?\n",
      "What is the purpose of scanning the data set for inconsistencies?\n",
      "What is the second part of the training phase?\n",
      "What is used to check the efficiency of the model?\n",
      "What is the classification algorithm used for?\n",
      "What can be done to improve the accuracy of the model?\n",
      "What is the name of the text that you want to use to answer the question?\n",
      "What is the third part of the testing phase?\n",
      "What is the purpose of such data?\n",
      "What is the name of the text that you want to use to?\n",
      "What is the last step of the model?\n",
      "What is the reason for inconsistencies?\n",
      "What are the insights and patterns derived during data exploration used to build?\n",
      "What is the second step of exploratory data analysis?\n",
      "?\n",
      "What is the first step of data preparation?\n",
      "What is the logic of the model based on?\n",
      "What is the third step of exploratory data analysis?\n",
      "What is the term for exploratory data analysis?\n",
      "What can be the output of the text?\n",
      "What is the step 5 building a machine learning model?\n",
      "What is the predicted value of a stock?\n",
      "What is the data needed for weather forecasting?\n",
      "What is the purpose of data exploration?\n",
      "What is the purpose of the text?\n",
      "What is the machine learning algorithm that is being implemented?\n",
      "What can be used to predict rainfall?\n",
      "Generated Questions:\n",
      "What is the model that can predict with the help of a labeled dataset?\n",
      "What is the most common type of machine learning?\n",
      "?\n",
      "What is the name of the text that you want to use to answer this question?\n",
      "What is the name of the question that you want to ask for the following text?\n",
      "What is supervised learning?\n",
      "What is the image labeled in the text?\n",
      "What are the images labeled in the text?\n",
      "What is the machine able to predict when a new image is fed to the machine without any label?\n",
      "What is the name of the machine that?\n",
      "What is a labeled dataset?\n",
      "What is the name of the machine that learns the association of images based on its features?\n",
      "What is fed to the machine that learns the association of images based on its features?\n",
      "Generated Questions:\n",
      "with 2 or more classes?\n",
      "What are blackmails used from already blacklisted spammers?\n",
      "What is classification?\n",
      "What is the most likely to be a scam?\n",
      "What does the spam filters look for?\n",
      "What is used to give it a spam score?\n",
      "What are the two categories of algorithms?\n",
      "What is used to score the mail?\n",
      "What are blackmails used from?\n",
      "What is a process of categorizing a given set of data into classes?\n",
      "What is the second category of algorithms?\n",
      "What is the question that you want to ask?\n",
      "What is done based on a lot of spam filters reviewing the content of the mail?\n",
      "What is one of the key use cases of demonstrating supervised machine learning?\n",
      "What is the name of the application of supervised learning signature recognition?\n",
      "What is the name of the category that categorizes text documents into?\n",
      "What is the name of the category that categorizes text documents into predefined categories?\n",
      "?\n",
      "What is used when the output variable is discrete or categorical i?\n",
      "e?\n",
      "What determines whether incoming mail should land in the inbox or spam folder?\n",
      "What is the classification used to predict?\n",
      "What is the name of the category that categorizes?\n",
      "with 2 or more?\n",
      "What is the first step in predicting whether a mail is spam?\n",
      "What can facebook recognize your friend in a picture from an album of tagged photos?\n",
      "Generated Questions:\n",
      "What is the answer to the question?\n",
      "What is the dependent variable in the text?\n",
      "What is visual recognition?\n",
      "What is a statistical method regression used when the output variable is a real or continuous value relationship between a dependent target and independent predictor variables with one or more independent variables?\n",
      "What can a machine predict based on the given temperature?\n",
      "What is the level of accuracy obtainable?\n",
      "How many words are in the question?\n",
      "What is the forecasting rainfall stock markets?\n",
      "What is the purpose of the training?\n",
      "What does the machine learn about the relationship between the variables?\n",
      "What is the salary based on work experience weight based on?\n",
      "What is the system fed with during its training phase?\n",
      "What is the purpose of the question?\n",
      "What is the purpose of the test data?\n",
      "What variables are included in the example?\n",
      "A change in one variable is associated with a change?\n",
      "?\n",
      "What does the humidity decrease if the temperature increases?\n",
      "What is the answer to the question that is asked for the following text?\n",
      "What is the aim of a supervised learning algorithm?\n",
      "What is the name of the variable that is fed to the model?\n",
      "Generated Questions:\n",
      "?\n",
      "What type of learning does the machine learn on itself without supervision?\n",
      "What type of learning is used in unsupervised learning?\n",
      "What does the machine give a response to?\n",
      "What does the machine do?\n",
      "What is the question that we do not tell the machine if its a spoon or knife?\n",
      "What type of learning does the machine use?\n",
      "What can unsupervised learning be further grouped into?\n",
      "What does the machine try to find in the unlabeled data?\n",
      "Generated Questions:\n",
      "What is the purpose of a personalized call and data plan?\n",
      "What is the method of dividing objects into clusters that are similar between them?\n",
      "What group will be given the benefit of both?\n",
      "What type of customers are heavy internet users?\n",
      "What are the strategies used to minimize churn rate?\n",
      "What group will be given cheaper called call rate plans?\n",
      "What is the association unsupervised learning?\n",
      "What is the method of dividing objects into clusters that are?\n",
      "What is the churn rate of a company?\n",
      "What is the relationship established based on?\n",
      "What is the name of the machine learning technique used to discover the probability of the cooccurrence of items in a collection?\n",
      "What type of customers do group a customers have high call durations?\n",
      "What does a customer buy in a supermarket?\n",
      "What is the most likely thing that a customer will buy if he buys bread?\n",
      "What is the name of the text that you want to find out about?\n",
      "?\n",
      "What is the recommendation made?\n",
      "What is the most likely thing that a customer will buy if he buys milk?\n",
      "What type of customers do group a customers use more data and have high call durations?\n",
      "What group will be given more data benefit plants?\n",
      "What does another customer buy?\n",
      "How does unsupervised learning work?\n",
      "What is the name of the text that you want to find out about the products that were purchased together?\n",
      "What is the goal of maximizing profit?\n",
      "What type of customers have high call duration?\n",
      "Generated Questions:\n",
      "What grouping of responses is used to ensure that the customer finds the information they want quickly and easily?\n",
      "How many data may a model require?\n",
      "What is a simpler method of learning?\n",
      "What does semantically similar words share a similar context?\n",
      "What is market basket analysis?\n",
      "What is the name of the question that is generated for the following text?\n",
      "What is a major drawback of machine learning?\n",
      "What is not known about the number of classes?\n",
      "What is the most commonly used unsupervised learning algorithm?\n",
      "What can be used to introduce safety measures based on the intensity of accidents?\n",
      "What is the less accurate and trustworthy method?\n",
      "What is needed to train models?\n",
      "What is semantic clustering?\n",
      "?\n",
      "What is the role of the browser in information retrieval?\n",
      "What is supervised learning?\n",
      "What is the most accurate method of learning?\n",
      "What is the most complex model?\n",
      "What can be used to identify accident prone areas?\n",
      "Generated Questions:\n",
      "What should the machine learning program be able to assess?\n",
      "What is the name of the text that can be used to learn to play games?\n",
      "What is the answer to the problem that is overcome by reinforcement learning?\n",
      "What might be the reason for the text to be outdated?\n",
      "What may not exist or we simply may not have access to it?\n",
      "What does the computer employ to come up with a solution to?\n",
      "What is a game like chess complicated because of?\n",
      "What are reinforcement learning algorithms called?\n",
      "What is important in a single action?\n",
      "What is the sequence of right moves that is good?\n",
      "What is good if it is part of a good policy?\n",
      "What might not be reliable?\n",
      "What is the name of the text that may not be available to us?\n",
      "What is the name of the text that you want to use to answer the question?\n",
      "What is a game like chess complicated?\n",
      "What is the name of the text that you want to use to?\n",
      "What might be wrong or missing in the text?\n",
      "What is a good example of game playing?\n",
      "What is important is the policy that is the sequence of correct actions to reach the goal?\n",
      "What should the machine learning program learn from past good action sequences to be able to generate a policy?\n",
      "?\n",
      "What is the output of the system?\n",
      "What is reinforcement learning?\n",
      "When not to use rl when you have enough data to solve the problem?\n",
      "What is a game like chess?\n",
      "What is a good move if it is part of a good game playing policy?\n",
      "What is the name of the action that is good if it is part of a good policy?\n",
      "Generated Questions:\n",
      "What is the robot diamond and fire?\n",
      "What is the agent supposed to find?\n",
      "What is the type of reinforcement learning classified into?\n",
      "What is negative defined as?\n",
      "What can reinforcement learning help enterprises plan how to allocate resources?\n",
      "What are the two types of reinforcement learning?\n",
      "What will the robot get for each right step?\n",
      "What is the goal of the robot?\n",
      "What does the robot choose?\n",
      "What is the type of positive positive reinforcement defined as?\n",
      "What is the total reward calculated when it reaches the final reward that is the diamond?\n",
      "What is the working of reinforcement learning example?\n",
      "What is the type?\n",
      "What has been used to teach bots to play a number of video games?\n",
      "What has been used to teach bots to play a number?\n",
      "What will the robot get for each wrong step?\n",
      "What is the definition of negative?\n",
      "What does the robot learn by trying all the possible paths?\n",
      "What is the agent supposed to find to reach the reward?\n",
      "?\n",
      "What is the final reward that will be calculated when it reaches the diamond?\n",
      "Generated Questions:\n",
      "?\n",
      "What is the name of the question that you want to ask for the following text?\n",
      "Generated Questions:\n",
      "?\n",
      "What is the name of the question that you want to ask for the following text?\n",
      "Generated Questions:\n",
      "?\n",
      "What is the name of the question that you want to ask for the following text?\n",
      "Generated Questions:\n",
      "What type of salary do data scientists command?\n",
      "?\n",
      "What can machine learning algorithms learn?\n",
      "What is the primary driver of internet companies' business models?\n",
      "What is the difference between supervised and unsupervised learning?\n",
      "What is the first disadvantage of a car?\n",
      "What type of infrastructure does a project require?\n",
      "What can be highcost?\n",
      "What can be the result of algorithms that are trained on data sets that exclude certain populations or contain errors?\n",
      "What can be the result of algorithms that are trained on data?\n",
      "What can lead to inaccurate models of the world that at best fail?\n",
      "What is the name of the question that you want to ask for the following text?\n",
      "What is the third disadvantage of a car?\n",
      "What does uber use to match drivers with riders?\n",
      "What is the second disadvantage of a car?\n",
      "What does google use to find the right ads in searches?\n",
      "What type of scientist is typically responsible for machine learning projects?\n",
      "What type of project is typically driven by data scientists?\n",
      "Generated Questions:\n",
      "What is the name of the question that you want to ask for the following text?\n",
      "What is the name of the google assistant siri cortana and alexa?\n",
      "What is one of the most common applications of machine learning?\n",
      "Machine learning is growing very rapidly day by day?\n",
      "What is a buzzword for todays technology?\n",
      "What does the algorithm behind face detection and recognition do?\n",
      "What is speech recognition also known as?\n",
      "What does machine learning do?\n",
      "What is speech recognition?\n",
      "What is the name of the google?\n",
      "What is the name of the application that google uses to search by voice?\n",
      "What is deep face responsible for?\n",
      "What is used to identify objects persons places digital images etc?\n",
      "What project is based on deep face?\n",
      "What is the name of the popular application of machine learning?\n",
      "?\n",
      "What is the current use of machine learning algorithms?\n",
      "What is the popular use case of image recognition and face detection?\n",
      "What does the technology behind tagging suggestions do?\n",
      "What is the popular use case of?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwiselinjayajos/t5-end2end-questions-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentences \u001b[38;5;129;01min\u001b[39;00m all_Sentence:\n\u001b[1;32m---> 35\u001b[0m     questions \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_questions_for_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Questions:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m question \u001b[38;5;129;01min\u001b[39;00m questions:\n",
      "Cell \u001b[1;32mIn[30], line 13\u001b[0m, in \u001b[0;36mgenerate_questions_for_list\u001b[1;34m(sentences, model, tokenizer, top_k, top_p)\u001b[0m\n\u001b[0;32m     10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(input_text_with_prefix, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs,\n\u001b[0;32m     15\u001b[0m         max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, \n\u001b[0;32m     16\u001b[0m         top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[0;32m     17\u001b[0m         top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m     18\u001b[0m         temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[0;32m     19\u001b[0m     )\n\u001b[0;32m     21\u001b[0m generated_question \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(outputs, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Split questions based on common sentence-ending punctuation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:1596\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[0;32m   1580\u001b[0m         input_ids,\n\u001b[0;32m   1581\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1592\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1593\u001b[0m     )\n\u001b[0;32m   1594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[0;32m   1595\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[1;32m-> 1596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgreedy_search(\n\u001b[0;32m   1597\u001b[0m         input_ids,\n\u001b[0;32m   1598\u001b[0m         logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[0;32m   1599\u001b[0m         stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[0;32m   1600\u001b[0m         pad_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mpad_token_id,\n\u001b[0;32m   1601\u001b[0m         eos_token_id\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39meos_token_id,\n\u001b[0;32m   1602\u001b[0m         output_scores\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39moutput_scores,\n\u001b[0;32m   1603\u001b[0m         return_dict_in_generate\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mreturn_dict_in_generate,\n\u001b[0;32m   1604\u001b[0m         synced_gpus\u001b[38;5;241m=\u001b[39msynced_gpus,\n\u001b[0;32m   1605\u001b[0m         streamer\u001b[38;5;241m=\u001b[39mstreamer,\n\u001b[0;32m   1606\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   1607\u001b[0m     )\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[0;32m   1610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\utils.py:2444\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[1;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[0;32m   2441\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m   2443\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[1;32m-> 2444\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_inputs,\n\u001b[0;32m   2446\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   2447\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   2448\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   2449\u001b[0m )\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   2452\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1746\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[1;32m-> 1746\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1756\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1757\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1761\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1763\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1123\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1110\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m checkpoint(\n\u001b[0;32m   1111\u001b[0m         create_custom_forward(layer_module),\n\u001b[0;32m   1112\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     )\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:695\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    693\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    705\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:602\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    593\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    599\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    600\u001b[0m ):\n\u001b[0;32m    601\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 602\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelfAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    611\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    612\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (hidden_states,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:574\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    571\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m*\u001b[39m layer_head_mask\n\u001b[0;32m    573\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m unshape(torch\u001b[38;5;241m.\u001b[39mmatmul(attn_weights, value_states))  \u001b[38;5;66;03m# (batch_size, seq_length, dim)\u001b[39;00m\n\u001b[1;32m--> 574\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m present_key_value_state \u001b[38;5;241m=\u001b[39m (key_states, value_states) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m use_cache) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    577\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (attn_output,) \u001b[38;5;241m+\u001b[39m (present_key_value_state,) \u001b[38;5;241m+\u001b[39m (position_bias,)\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\sriyo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def generate_questions_for_list(sentences, model, tokenizer, top_k=50, top_p=0.95):\n",
    "    generated_questions=set()\n",
    "    for sentence in sentences:\n",
    "        input_text_with_prefix=f\"Generate a question for the following text: {sentence}\"\n",
    "        inputs=tokenizer(input_text_with_prefix, return_tensors=\"pt\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs=model.generate(\n",
    "                **inputs,\n",
    "                max_length=50, \n",
    "                top_k=top_k,\n",
    "                top_p=top_p,\n",
    "                temperature=1.0,\n",
    "            )\n",
    "\n",
    "        generated_question=tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        split_questions=[question.strip()+'?' for question in re.split(r'[.!?]',generated_question[0])]\n",
    "        generated_questions.update(split_questions)\n",
    "    return generated_questions\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(\"wiselinjayajos/t5-end2end-questions-generation\")\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(\"wiselinjayajos/t5-end2end-questions-generation\")\n",
    "\n",
    "for sentences in all_Sentence:\n",
    "    questions=generate_questions_for_list(sentences, model, tokenizer, top_k=50, top_p=0.95)\n",
    "    print(\"Generated Questions:\")\n",
    "    for question in questions:\n",
    "        print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
